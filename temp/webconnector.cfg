[License]
LicenseServerHost=10.24.1.220
LicenseServerACIPort=20000

[Service]
ServicePort=17006
ServiceStatusClients=*
ServiceControlClients=::1,127.0.0.1

[Server]
Port=7006
QueryClients=*
AdminClients=::1,127.0.0.1
XSLTemplates=TRUE

[Logging]
LogLevel=FULL
LogEcho=TRUE
0=ApplicationLogStream
1=ActionLogStream
2=SynchronizeLogStream

[ApplicationLogStream]
LogFile=application.log
LogTypeCSVs=application

[ActionLogStream]
LogFile=action.log
LogTypeCSVs=action

[SynchronizeLogStream]
LogFile=synchronize.log
LogTypeCSVs=synchronize

[Connector]
EnableIngestion=TRUE
EnableScheduledTasks=TRUE
ScheduleRepeatSecs=86400
ScheduleCycles=-1

[Ingestion]
IngesterType=CFS
IngestHost=localhost
IngestPort=8082
//IngestCFS=7000
IndexDatabase=missur_test

[FetchTasks]
SSLMethod=SSLV23
Number=1
0=MyTask0

//example

[MyTask0]
//The url(s) from which to start the crawl.
Url=https://biz.censor.net.ua/news/3035649/rejisser_universalnogo_soldata_i_godzilly_otkroet_filial_svoeyi_kompanii_v_kieve
//Regexes to restrict pages that are crawled for links. If a page is not crawled, it will not be indexed.
SpiderUrlMustHaveRegex=
IngestAction0=META:CUSTOMER-RNID=T00001000000210001
IngestAction1=META:CUSTOMER-CNID=lombard-g
SpiderUrlCantHaveRegex=.*\.css$|.*.css\?.*$|.*\.js$|.*\.js,.*$|.*.js\?.*
//Regexes to restrict pages that are indexed.
UrlMustHaveRegex=
UrlCantHaveRegex=
PageMustHaveRegex=.*Киев.*
PageCantHaveRegex=
ContentTypeMustHaveRegex=
ContentTypeCantHaveRegex=(application|text)/(javascript|xml|x-javascript|css)(;.*)?
//The delay between processing pages, per sync thread
PageDelay=5s
//If StayOnSite=true, all links that are followed on a page must be on the same in order site to be crawled
StayOnSite=true
//Maximum ammount of time to spend crawling, 0 indicating unlimited
SiteDuration=0s
//Maximum number of pages to ingest per synchronize run, 0 indicating unlimited
MaxPages=0
//Minimum size that a page must be for it to be ingested
MinPageSize=0
//Maximum size that a page must be for it to be ingested, 0 indicating unlimited
MaxPageSize=0
//Maximum number of links a page can have before it is not ingested, 0 indicating unlimited
MaxLinksPerPage=0
//Follow robots.txt and ROBOTS meta tag commands
FollowRobotProtocol=true
//The UserAgent sent in the request headers
SpiderAs=Autn-WKOOP
//Maximumdepth to spider to, -1 indicating unlimited.
Depth=0
//Follow links found in flash content
FollowFlash=false
//Regexes to restrict which element types are crawled for links
LinkElementMustHaveRegex=^a$
LinkElementCantHaveRegex=
//HTML tag attribute names to be treated as containing a link to be followed
LinkAttributes=href
//Enable web page clipping
Clipped=false
//If Clipped=true, the area of the page that is kept/removed can be specified using these css2 selectors.
//If these are left empty, the SmartPrint algorithm is used to determine which parts of the page are kept/removed.
ClipPageUsingCssSelect=
ClipPageUsingCssUnselect=
//Ignore canonical links in web page headers or meta tags
IgnoreCanonicalLinks=false
//Include a metadata field for each <meta name=".." content="..." /> element in the html head.
IncludeMetaTagsInMetadata=false
//Include a LINK metadata field for each link found on a page
IncludeLinksInMetadata=true
//Extract custom metadata from each page using css2 selectors.
MetadataSelector0=
MetadataFieldName0=
//Extract plain text from the HTML elements identified by the MetadataSelector parameters above
MetadataSelectorExtractPlainText=false
//Remove all <script> elements from indexed pages.
RemoveScripts=true
//Remove all <noscript> elements from indexed pages.
RemoveNoscripts=true
//Remove all <noframes> elements from indexed pages.
RemoveNoframes=true
//Proxy details
ProxyHost=
ProxyPort=
ProxyUser=
ProxyPassword=
//Authentication details sent if 401 is returned by the server.
//Supports Basic, NTLM V2 and Digest-MD5.
AuthUser=
AuthPassword=

[Paths]
AdminFile=C:\HewlettPackardEnterprise\IDOLServer-11.3.0/common/admin.dat

